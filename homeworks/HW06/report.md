# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (10000, 30)
- Целевая переменная: `target` (бинарная классификация); доли классов: ~0.75 для класса 0, ~0.25 для класса 1
- Признаки: все признаки числовые; присутствуют несколько «категориальных-подобных» полей с малым числом уникальных целых значений (например, столбцы с индексами 25–27), что характерно для закодированных категорий

## 2. Protocol

- Разбиение: train/test = 80/20 с `random_state=42` и `stratify=y` — обеспечивает воспроизводимость и сохранение пропорций классов в обеих выборках
- Подбор: GridSearchCV с 5 фолдами на обучающей части (`X_train`, `y_train`); оптимизировалась метрика `f1` (уместна при умеренном дисбалансе)
- Метрики: `accuracy`, `f1`, `ROC-AUC`. Эти метрики уместны, так как задача — бинарная классификация, и ROC-AUC позволяет оценить качество ранжирования вне зависимости от порога, а F1 учитывает дисбаланс классов

## 3. Models

Сравнивались следующие модели:

- **DummyClassifier** (`strategy='most_frequent'`) — простейший baseline
- **LogisticRegression** — baseline из S05, использовался через Pipeline со StandardScaler
- **DecisionTreeClassifier** — подбирались гиперпараметры `max_depth` ∈ {3, 5, 7, 10} и `min_samples_leaf` ∈ {5, 10, 20} для контроля переобучения
- **RandomForestClassifier** — подбирались `n_estimators` ∈ {50, 100}, `max_depth` ∈ {5, 10}, `min_samples_leaf` ∈ {5, 10}
- **GradientBoostingClassifier** — подбирались `n_estimators` ∈ {50, 100}, `max_depth` ∈ {3, 5}, `learning_rate` ∈ {0.05, 0.1}

## 4. Results

Финальные метрики на test:

```json
{
  "Dummy": {"accuracy": 0.75, "f1": 0.0, "roc_auc": 0.5},
  "LogisticRegression": {"accuracy": 0.82, "f1": 0.51, "roc_auc": 0.86},
  "DecisionTree": {"accuracy": 0.84, "f1": 0.58, "roc_auc": 0.89},
  "RandomForest": {"accuracy": 0.87, "f1": 0.65, "roc_auc": 0.92},
  "GradientBoosting": {"accuracy": 0.88, "f1": 0.67, "roc_auc": 0.93}
}
```

Победитель: **GradientBoostingClassifier** по ROC-AUC (0.93) и F1 (0.67). Это ожидаемо: boosting-методы часто показывают высокое качество на синтетических данных с умеренным шумом.

## 5. Analysis

- **Устойчивость**: при нескольких запусках с разными `random_state` (5 прогонов) значения ROC-AUC для GradientBoosting колебались в пределах ±0.01, что говорит о стабильности результата.\\
- **Ошибки**: confusion matrix для GradientBoosting показывает хорошее разделение классов: большинство объектов класса 1 правильно предсказаны, ложных срабатываний немного. Это подтверждает адекватность модели при умеренном дисбалансе.\\
- **Интерпретация**: permutation importance выявила топ-10 признаков. Наибольшее влияние оказывают `num19` и `num18`, за ними следуют `num07`, `num04` и группа признаков `num16`–`num24`. Это согласуется с тем, что последние признаки имитируют категориальные переменные с малым числом уникальных значений — такие признаки деревья обрабатывают особенно эффективно.

## 6. Conclusion

1. Деревья легко переобучаются без ограничения глубины или `min_samples_leaf`, но их можно контролировать через гиперпараметры.
2. Ансамбли (Random Forest, Gradient Boosting) значительно улучшают качество по сравнению с одиночным деревом и логистической регрессией.
3. Честный ML-протокол (фиксированный сплит, CV только на train, оценка на test один раз) критически важен для объективного сравнения моделей.
4. ROC-AUC и F1 дают более полную картину качества, чем accuracy, особенно при дисбалансе.
5. Permutation importance — надёжный способ интерпретации даже сложных моделей, таких как градиентный бустинг.